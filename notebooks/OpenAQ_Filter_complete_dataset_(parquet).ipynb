{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gSWdXLx-esM"
      },
      "source": [
        "## OpenAQ - Filtrage du dataset via SQL (DuckDB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fw3M_UypVGOb"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# INPUTS: change depending on the data you're working with\n",
        "\n",
        "import os\n",
        "from openaq_anomaly_prediction.config import Configuration as cfg\n",
        "\n",
        "PARQUET_FILEPATH = os.path.join(cfg.DATA_EXPORT_PATH, \"seoul_complete.int.parquet\")\n",
        "CITY_TIMEZONE = \"Asia/Seoul\"  # available for each row/location"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-oLDv12B__e"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbS1h1-qBr5T",
        "outputId": "bc9284bb-17ec-4249-bdca-c3d34461c789"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_duckdb.DuckDBPyConnection at 0x745af0aafc30>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ================================================================\n",
        "# IMPORTS: python packages and settings (don't change anything)\n",
        "\n",
        "import duckdb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "import pyarrow.dataset as ds\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "# CONFIG: to display all rows/columns of a dataframe (debug)\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "pd.set_option(\"display.max_rows\", None)\n",
        "pd.set_option(\"display.width\", 1000)\n",
        "sep_length = 64  # Only so we can print separators of a fixed length\n",
        "\n",
        "# PyArrow\n",
        "parquet_file = pq.ParquetFile(PARQUET_FILEPATH)\n",
        "\n",
        "# DuckDB:\n",
        "con = duckdb.connect()\n",
        "# con.execute(f\"SET TimeZone='{CITY_TIMEZONE}';\")  # available for each row/location, no need to set globally\n",
        "con.execute(f\"CREATE OR REPLACE VIEW measurements AS SELECT * FROM read_parquet('{PARQUET_FILEPATH}')\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "STXQtn4vdL4y"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# UTILS: helper functions (don't change anything)\n",
        "\n",
        "def print_summary(df: pd.DataFrame) -> None:\n",
        "    \"\"\"Print a summary of the useful stats of a dataframe.\"\"\"\n",
        "    # Summary\n",
        "    print(f\"{'='*sep_length}\\nSUMMARY: Custom DataFrame\\n{'-'*sep_length}\")\n",
        "    print(f\"Total rows: {len(df)}\")\n",
        "    print(f\"From: {df[\"period.datetimeTo.local\"].min()}\")\n",
        "    print(f\"To  : {df[\"period.datetimeTo.local\"].max()}\")\n",
        "    print(f\"{'-'*int(sep_length/3)*2}\")\n",
        "    print(f\"Unique locations: {df[\"location_id\"].nunique()}\")\n",
        "    print(f\"Unique pollutants: {df[\"name\"].nunique()}\")\n",
        "    print(f\"{'-'*int(sep_length/3)*2}\")\n",
        "    for pollutant in df[\"name\"].unique():\n",
        "        print(f\"> {pollutant}\")\n",
        "\n",
        "def print_summary_timeseries(df: pd.DataFrame) -> None:\n",
        "    \"\"\"Print a summary of the useful stats of a TIME-SERIES dataframe.\"\"\"\n",
        "\n",
        "    memory_usage = df.memory_usage(index=True, deep=True).sum() / (1024**2)\n",
        "\n",
        "    # Summary\n",
        "    print(f\"{'='*sep_length}\\nSUMMARY: Time-series DataFrame\\n{'-'*sep_length}\")\n",
        "    print(f\"Total rows  : {len(df)}\")\n",
        "    print(f\"Memory usage: {memory_usage:.2f} MB\")\n",
        "    print(f\"From: {df[\"datetimeTo_local\"].min()}\")\n",
        "    print(f\"To  : {df[\"datetimeTo_local\"].max()}\")\n",
        "    print(f\"{'-'*int(sep_length/3)*2}\")\n",
        "    print(f\"Unique locations: {df[\"location_id\"].nunique()}\")\n",
        "    print(f\"Unique pollutants: {df[\"name\"].nunique()}\")\n",
        "    print(f\"{'-'*int(sep_length/3)*1}\")\n",
        "    for pollutant in df[\"name\"].unique():\n",
        "        print(f\"> {pollutant}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5F8dB-HJeig2"
      },
      "source": [
        "### Résumé du fichier de base (parquet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbXm6eM6Fnzz",
        "outputId": "529a9428-2d40-4ed3-a5da-275f788c99a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================\n",
            "SUMMARY: /home/deniscck/code/denis-cck/openaq_anomaly_prediction/data/export/seoul_complete.int.parquet\n",
            "----------------------------------------------------------------\n",
            "Total rows: 4918548\n",
            "From: 2024-04-30 17:00:00+02:00\n",
            "To  : 2025-12-16 03:00:00+01:00\n",
            "------------------------------------------\n",
            "Unique locations: 58\n",
            "Unique pollutants: 6\n",
            "------------------------------------------\n",
            "> o3 ppm\n",
            "> co ppm\n",
            "> pm25 µg/m³\n",
            "> pm10 µg/m³\n",
            "> no2 ppm\n",
            "> so2 ppm\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# SUMMARY: for information only (don't change anything)\n",
        "\n",
        "# DuckDB\n",
        "db_start_date = con.execute(\"\"\"\n",
        "    SELECT min(\"period.datetimeTo.local\")\n",
        "    FROM measurements\n",
        "\"\"\", {}).fetchone()[0]\n",
        "\n",
        "db_end_date = con.execute(\"\"\"\n",
        "    SELECT max(\"period.datetimeTo.local\")\n",
        "    FROM measurements\n",
        "\"\"\", {}).fetchone()[0]\n",
        "\n",
        "db_unique_locations_count = con.execute(\"\"\"\n",
        "    SELECT count(DISTINCT \"location_id\")\n",
        "    FROM measurements\n",
        "\"\"\", {}).fetchone()[0]\n",
        "\n",
        "db_unique_pollutants_count = con.execute(\"\"\"\n",
        "    SELECT count(DISTINCT \"name\")\n",
        "    FROM measurements\n",
        "\"\"\", {}).fetchone()[0]\n",
        "\n",
        "db_unique_pollutants = con.execute(\"\"\"\n",
        "    SELECT DISTINCT \"name\"\n",
        "    FROM measurements\n",
        "\"\"\", {}).fetchnumpy()[\"name\"].tolist()  # could use a list comprehension too\n",
        "#\"\"\", {}).df().values.flatten()\n",
        "\n",
        "# Summary\n",
        "print(f\"{'='*sep_length}\\nSUMMARY: {PARQUET_FILEPATH}\\n{'-'*sep_length}\")\n",
        "print(f\"Total rows: {parquet_file.metadata.num_rows}\")\n",
        "print(f\"From: {db_start_date}\")\n",
        "print(f\"To  : {db_end_date}\")\n",
        "print(f\"{'-'*int(sep_length/3)*2}\")\n",
        "print(f\"Unique locations: {db_unique_locations_count}\")\n",
        "print(f\"Unique pollutants: {db_unique_pollutants_count}\")\n",
        "print(f\"{'-'*int(sep_length/3)*2}\")\n",
        "for pollutant in db_unique_pollutants:\n",
        "    print(f\"> {pollutant}\")\n",
        "print()\n",
        "\n",
        "# Display a list of all columns available in the dataframe\n",
        "# print(\"Available Columns:\")\n",
        "# pprint(parquet_file.schema.names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6WXD9syg5gt"
      },
      "source": [
        "### Exemples de filtres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-sciaTkXnJFL"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# SELECT the columns (use -- to comment out a column or /* */ for multiline)\n",
        "\n",
        "query = \"\"\"\n",
        "    CREATE OR REPLACE VIEW bronze_measurements AS\n",
        "    SELECT\n",
        "        location_id,\n",
        "        sensor_id,\n",
        "        name,\n",
        "        value,\n",
        "\n",
        "        \"period.datetimeFrom.local\",\n",
        "        \"period.datetimeFrom.local\",\n",
        "        \"period.datetimeTo.local\",\n",
        "        \"period.datetimeTo.utc\",\n",
        "        \"datetimeWeather.local\",\n",
        "        timezone,\n",
        "        \"coordinates.latitude\",\n",
        "        \"coordinates.longitude\",\n",
        "\n",
        "        -- parameter.id,\n",
        "        -- parameter.name,\n",
        "        -- parameter.units,\n",
        "        \"parameter.displayName\",\n",
        "\n",
        "        -- period.datetimeFrom.utc,\n",
        "        -- location.datetimeFirst.utc,\n",
        "        -- location.datetimeLast.utc,\n",
        "        -- timestampTo,\n",
        "\n",
        "        -- location_name,\n",
        "        -- country.code,\n",
        "        -- owner.name,\n",
        "        -- provider.name,\n",
        "        -- datetimeWeather.utc,\n",
        "        -- weather_latitude,\n",
        "        -- weather_longitude,\n",
        "\n",
        "        elevation,\n",
        "        temperature_2m,\n",
        "        relative_humidity_2m,\n",
        "        dew_point_2m,\n",
        "        apparent_temperature,\n",
        "        precipitation,\n",
        "        rain,\n",
        "        snowfall,\n",
        "        snow_depth,\n",
        "        shortwave_radiation,\n",
        "        direct_radiation,\n",
        "        diffuse_radiation,\n",
        "        global_tilted_irradiance,\n",
        "        direct_normal_irradiance,\n",
        "        terrestrial_radiation,\n",
        "        weather_code,\n",
        "        pressure_msl,\n",
        "        surface_pressure,\n",
        "        cloud_cover,\n",
        "        cloud_cover_low,\n",
        "        cloud_cover_mid,\n",
        "        cloud_cover_high,\n",
        "        vapour_pressure_deficit,\n",
        "        et0_fao_evapotranspiration,\n",
        "        wind_speed_100m,\n",
        "        wind_speed_10m,\n",
        "        wind_direction_10m,\n",
        "        wind_direction_100m,\n",
        "        wind_gusts_10m,\n",
        "        is_day,\n",
        "\n",
        "    FROM measurements\n",
        "\"\"\"\n",
        "\n",
        "custom_df = con.execute(query, {}).df()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8ObFttq9g4eH"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# FILTERS: create filters corresponding to SQL syntax (DuckDB)\n",
        "# Here are examples of what you can do, take it in your own hands\n",
        "# or get help with your favourite AI friend.\n",
        "\n",
        "def dont_run_its_an_example() -> None:\n",
        "\n",
        "    # -------------------------------------------------------------\n",
        "    # Filter by DATE (be mindful of timezones)\n",
        "    query = \"\"\"\n",
        "        SELECT\n",
        "            *\n",
        "        FROM bronze_measurements\n",
        "        WHERE \"period.datetimeTo.local\" >= $start_date\n",
        "          AND \"period.datetimeTo.local\" <= $end_date\n",
        "    \"\"\"\n",
        "    custom_df = con.execute(query, {\n",
        "        \"start_date\": \"2025-01-01 00:00:00+09:00\",\n",
        "        \"end_date\": \"2025-12-31 23:59:59+09:00\"\n",
        "    }).df()\n",
        "\n",
        "    # -------------------------------------------------------------\n",
        "    # Filter by LOCATION_ID\n",
        "\n",
        "    # This works perfectly fine in modern DuckDB\n",
        "    query = \"\"\"\n",
        "        SELECT\n",
        "            *\n",
        "        FROM bronze_measurements\n",
        "        WHERE location_id IN $location_ids\n",
        "    \"\"\"\n",
        "    # This is \"better\" because it turns the list in a temporary table\n",
        "    query = \"\"\"\n",
        "        SELECT\n",
        "            *\n",
        "        FROM bronze_measurements\n",
        "        WHERE location_id IN (SELECT unnest($location_ids))\n",
        "    \"\"\"\n",
        "\n",
        "    custom_df = con.execute(query, {\n",
        "        \"location_ids\": [2622825, 2623440, 2623080],\n",
        "    }).df()\n",
        "\n",
        "    # -------------------------------------------------------------\n",
        "    # Filter by POLLUTANT (\"name\")\n",
        "\n",
        "    # Same as LOCATION_ID\n",
        "    query = \"\"\"\n",
        "        SELECT\n",
        "            *\n",
        "        FROM bronze_measurements\n",
        "        WHERE name IN (SELECT unnest($pollutants))\n",
        "    \"\"\"\n",
        "    custom_df = con.execute(query, {\n",
        "        \"pollutants\": [\"pm25 µg/m³\", \"pm10 µg/m³\"],\n",
        "    }).df()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3oNRX3fem51"
      },
      "source": [
        "### Création du dataframe personnalisé"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZkbNL9lEnbN",
        "outputId": "31de398c-700b-48b2-a193-73c4e761eb29"
      },
      "outputs": [],
      "source": [
        "#  # -------------------------------------------------------------\n",
        "# # Query Example\n",
        "\n",
        "# query = \"\"\"\n",
        "#     SELECT\n",
        "#         \"period.datetimeTo.local\",\n",
        "#         \"datetimeWeather.local\"\n",
        "#     FROM bronze_measurements\n",
        "#     WHERE value < 10000\n",
        "#       AND \"period.datetimeTo.local\" >= $start_date\n",
        "#       AND \"period.datetimeTo.local\" <= $end_date\n",
        "#       -- AND location_id IN (SELECT unnest($location_ids))\n",
        "#       -- AND name IN (SELECT unnest($pollutants))\n",
        "# \"\"\"\n",
        "# custom_df = con.execute(query, {\n",
        "#     \"start_date\": \"2025-12-01 00:00:00+09:00\",\n",
        "#     \"end_date\": \"2025-12-31 23:59:59+09:00\",\n",
        "#     # \"location_ids\": [2622825, 2623440, 2623080],\n",
        "#     # \"pollutants\": [\"pm25 µg/m³\"],\n",
        "# }).df()\n",
        "\n",
        "# # Stats\n",
        "# memory_usage = custom_df.memory_usage(index=True, deep=True).sum() / (1024**2)\n",
        "# print(f\"Number of rows: {len(custom_df)}\")\n",
        "# print(f\"Memory usage: {memory_usage:.2f} MB\")\n",
        "# # print_summary(custom_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Check if the two datetime columns are equal (measurements vs weather)\n",
        "# test_df = custom_df[\"period.datetimeTo.local\"] != custom_df[\"datetimeWeather.local\"]\n",
        "# test_df.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "IddFxCrB40y9",
        "outputId": "30ac90d4-47a4-48b9-ac64-dc7b8ea26d56"
      },
      "outputs": [],
      "source": [
        "# sns.lineplot(data=custom_df, x=\"period.datetimeTo.local\", y=\"value\")\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoZIkFyw-w5z"
      },
      "source": [
        "### DuckDB Views"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# TIME-SERIES: BRONZE\n",
        "\n",
        "query = \"\"\"\n",
        "    CREATE OR REPLACE VIEW bronze_timeseries AS\n",
        "    SELECT\n",
        "        location_id,\n",
        "        sensor_id,\n",
        "        \"parameter.displayName\" AS displayName,\n",
        "        name,\n",
        "        value,\n",
        "\n",
        "        (\"period.datetimeTo.utc\" AT TIME ZONE 'UTC')::TIMESTAMP AS datetimeTo_utc,\n",
        "        (\"period.datetimeTo.local\" AT TIME ZONE timezone)::TIMESTAMP AS datetimeTo_local,\n",
        "        (\"datetimeWeather.local\" AT TIME ZONE timezone)::TIMESTAMP AS datetimeWeather_local,\n",
        "        -- timezone(timezone, \"period.datetimeTo.local\") AS datetimeTo_local,\n",
        "        -- timezone('UTC', \"period.datetimeTo.utc\") AS datetimeTo_utc,\n",
        "        -- timezone(timezone, \"datetimeWeather.local\") AS datetimeWeather_local,\n",
        "        -- timezone,\n",
        "\n",
        "        \"coordinates.latitude\" AS latitude,\n",
        "        \"coordinates.longitude\" AS longitude,\n",
        "\n",
        "        -- parameter.id,\n",
        "        -- parameter.name,\n",
        "        -- parameter.units,\n",
        "\n",
        "        -- period.datetimeFrom.utc,\n",
        "        -- location.datetimeFirst.utc,\n",
        "        -- location.datetimeLast.utc,\n",
        "        -- timestampTo,\n",
        "\n",
        "        -- location_name,\n",
        "        -- country.code,\n",
        "        -- owner.name,\n",
        "        -- provider.name,\n",
        "        -- datetimeWeather.utc,\n",
        "        -- weather_latitude,\n",
        "        -- weather_longitude,\n",
        "\n",
        "        elevation,\n",
        "        temperature_2m,\n",
        "        relative_humidity_2m,\n",
        "        dew_point_2m,\n",
        "        apparent_temperature,\n",
        "        precipitation,\n",
        "        rain,\n",
        "        snowfall,\n",
        "        snow_depth,\n",
        "        shortwave_radiation,\n",
        "        direct_radiation,\n",
        "        diffuse_radiation,\n",
        "        global_tilted_irradiance,\n",
        "        direct_normal_irradiance,\n",
        "        terrestrial_radiation,\n",
        "        weather_code,\n",
        "        pressure_msl,\n",
        "        surface_pressure,\n",
        "        cloud_cover,\n",
        "        cloud_cover_low,\n",
        "        cloud_cover_mid,\n",
        "        cloud_cover_high,\n",
        "        vapour_pressure_deficit,\n",
        "        et0_fao_evapotranspiration,\n",
        "        wind_speed_100m,\n",
        "        wind_speed_10m,\n",
        "        wind_direction_10m,\n",
        "        wind_direction_100m,\n",
        "        wind_gusts_10m,\n",
        "        is_day,\n",
        "\n",
        "    FROM measurements\n",
        "\"\"\"\n",
        "custom_df = con.execute(query, {}).df()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# TIME-SERIES: SILVER\n",
        "\n",
        "query = \"\"\"\n",
        "    CREATE OR REPLACE VIEW silver_timeseries AS\n",
        "    SELECT\n",
        "\n",
        "    -- MEASUREMENTS ==========================\n",
        "\n",
        "        /* SENSOR METADATA                  */\n",
        "            location_id,\n",
        "            sensor_id,\n",
        "            -- displayName,\n",
        "            name,\n",
        "\n",
        "        /* POLLUTANT FEATURES               */\n",
        "            -- Set values >= 10,000 to NULL for imputation later\n",
        "            CAST(CASE WHEN value >= 10000 THEN NULL ELSE value END AS DOUBLE) AS value,\n",
        "\n",
        "        /* TIME FEATURES                    */\n",
        "            datetimeTo_utc,\n",
        "            datetimeTo_local,\n",
        "            datetimeWeather_local,\n",
        "        \n",
        "        /* LOCATION FEATURES                */\n",
        "            latitude,\n",
        "            longitude,\n",
        "            elevation,\n",
        "\n",
        "    -- WEATHER ===============================\n",
        "        /* ATMOSPHERIC FEATURES             */\n",
        "            temperature_2m,\n",
        "            relative_humidity_2m,\n",
        "            dew_point_2m,\n",
        "            apparent_temperature,\n",
        "            pressure_msl,\n",
        "            surface_pressure,\n",
        "            weather_code,\n",
        "\n",
        "        /* PRECIPITATION FEATURES           */\n",
        "            precipitation,\n",
        "            rain,\n",
        "            snowfall,\n",
        "            snow_depth,\n",
        "\n",
        "        /* RADIATION/DAYLIGHT FEATURES      */\n",
        "            shortwave_radiation,\n",
        "            direct_radiation,\n",
        "            diffuse_radiation,\n",
        "            global_tilted_irradiance,\n",
        "            direct_normal_irradiance,\n",
        "            terrestrial_radiation,\n",
        "            is_day,\n",
        "\n",
        "        /* CLOUD & MOISTURE FEATURES        */\n",
        "            cloud_cover,\n",
        "            cloud_cover_low,\n",
        "            cloud_cover_mid,\n",
        "            cloud_cover_high,\n",
        "            vapour_pressure_deficit,\n",
        "            et0_fao_evapotranspiration,\n",
        "\n",
        "        /* WIND FEATURES                    */\n",
        "            wind_speed_100m,\n",
        "            wind_speed_10m,\n",
        "            wind_direction_10m,\n",
        "            wind_direction_100m,\n",
        "            wind_gusts_10m,\n",
        "\n",
        "    FROM bronze_timeseries\n",
        "\"\"\"\n",
        "custom_df = con.execute(query, {}).df()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1WNT6RUW-zt0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================\n",
            "SUMMARY: Time-series DataFrame\n",
            "----------------------------------------------------------------\n",
            "Total rows  : 819758\n",
            "Memory usage: 296.30 MB\n",
            "From: 2024-05-01 00:00:00\n",
            "To  : 2025-12-16 11:00:00\n",
            "------------------------------------------\n",
            "Unique locations: 58\n",
            "Unique pollutants: 1\n",
            "---------------------\n",
            "> pm25 µg/m³\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 819758 entries, 0 to 819757\n",
            "Data columns (total 39 columns):\n",
            " #   Column                      Non-Null Count   Dtype         \n",
            "---  ------                      --------------   -----         \n",
            " 0   location_id                 819758 non-null  int64         \n",
            " 1   sensor_id                   819758 non-null  int64         \n",
            " 2   name                        819758 non-null  object        \n",
            " 3   value                       779644 non-null  float64       \n",
            " 4   datetimeTo_utc              819758 non-null  datetime64[us]\n",
            " 5   datetimeTo_local            819758 non-null  datetime64[us]\n",
            " 6   datetimeWeather_local       819758 non-null  datetime64[us]\n",
            " 7   latitude                    819758 non-null  float64       \n",
            " 8   longitude                   819758 non-null  float64       \n",
            " 9   elevation                   819758 non-null  float64       \n",
            " 10  temperature_2m              819758 non-null  float64       \n",
            " 11  relative_humidity_2m        819758 non-null  int64         \n",
            " 12  dew_point_2m                819758 non-null  float64       \n",
            " 13  apparent_temperature        819758 non-null  float64       \n",
            " 14  pressure_msl                819758 non-null  float64       \n",
            " 15  surface_pressure            819758 non-null  float64       \n",
            " 16  weather_code                819758 non-null  int64         \n",
            " 17  precipitation               819758 non-null  float64       \n",
            " 18  rain                        819758 non-null  float64       \n",
            " 19  snowfall                    819758 non-null  float64       \n",
            " 20  snow_depth                  819758 non-null  float64       \n",
            " 21  shortwave_radiation         819758 non-null  float64       \n",
            " 22  direct_radiation            819758 non-null  float64       \n",
            " 23  diffuse_radiation           819758 non-null  float64       \n",
            " 24  global_tilted_irradiance    819758 non-null  float64       \n",
            " 25  direct_normal_irradiance    819758 non-null  float64       \n",
            " 26  terrestrial_radiation       819758 non-null  float64       \n",
            " 27  is_day                      819758 non-null  int64         \n",
            " 28  cloud_cover                 819758 non-null  int64         \n",
            " 29  cloud_cover_low             819758 non-null  int64         \n",
            " 30  cloud_cover_mid             819758 non-null  int64         \n",
            " 31  cloud_cover_high            819758 non-null  int64         \n",
            " 32  vapour_pressure_deficit     819758 non-null  float64       \n",
            " 33  et0_fao_evapotranspiration  819758 non-null  float64       \n",
            " 34  wind_speed_100m             819758 non-null  float64       \n",
            " 35  wind_speed_10m              819758 non-null  float64       \n",
            " 36  wind_direction_10m          819758 non-null  int64         \n",
            " 37  wind_direction_100m         819758 non-null  int64         \n",
            " 38  wind_gusts_10m              819758 non-null  float64       \n",
            "dtypes: datetime64[us](3), float64(24), int64(11), object(1)\n",
            "memory usage: 243.9+ MB\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# Query last view\n",
        "\n",
        "query = \"\"\"\n",
        "    SELECT\n",
        "        *\n",
        "    FROM silver_timeseries\n",
        "    -- WHERE value < 1000000 -- don't do that, instead put the 10k values to NaN for imputing\n",
        "    WHERE datetimeTo_local >= $start_date\n",
        "      AND datetimeTo_local <= $end_date\n",
        "      -- AND location_id IN (SELECT unnest($location_ids))\n",
        "      AND name IN (SELECT unnest($pollutants))\n",
        "\"\"\"\n",
        "timeseries_df = con.execute(query, {\n",
        "    \"start_date\": \"2024-01-01 00:00:00+09:00\",\n",
        "    \"end_date\": \"2025-12-31 23:59:59+09:00\",\n",
        "    # \"location_ids\": [2622825, 2623440, 2623080],\n",
        "    \"pollutants\": [\"pm25 µg/m³\"],\n",
        "}).df()\n",
        "\n",
        "# Stats\n",
        "print_summary_timeseries(timeseries_df)\n",
        "timeseries_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Outliers (value == 10000): 0.00% (0/819758)\n",
            "NaN values: 4.89% (40114/819758)\n"
          ]
        }
      ],
      "source": [
        "total_count = len(timeseries_df)\n",
        "outliers_count = len(timeseries_df[timeseries_df[\"value\"] == 10000])\n",
        "print(f\"Outliers (value == 10000): {outliers_count/total_count:.2%} ({outliers_count}/{total_count})\")\n",
        "print(f\"NaN values: {timeseries_df['value'].isna().sum()/total_count:.2%} ({timeseries_df['value'].isna().sum()}/{total_count})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# timeseries_df[timeseries_df['value'].isna()].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# custom_df.info()\n",
        "# display(custom_df.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Baseline: Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Just for the baseline we remove everything NaN\n",
        "removed_nan_indices = timeseries_df.dropna()\n",
        "\n",
        "X = removed_nan_indices.drop(columns=[\"value\"])\n",
        "y = removed_nan_indices[\"value\"].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (623715, 38) (NaN: 0)\n",
            "X_test shape: (155929, 38) (NaN: 0)\n",
            "y_train shape: (623715,) (NaN: 0)\n",
            "y_test shape: (155929,) (NaN: 0)\n"
          ]
        }
      ],
      "source": [
        "print(f\"X_train shape: {X_train.shape} (NaN: {X_train.isna().sum().sum()})\")\n",
        "print(f\"X_test shape: {X_test.shape} (NaN: {X_test.isna().sum().sum()})\")\n",
        "print(f\"y_train shape: {y_train.shape} (NaN: {np.isnan(y_train).sum()})\")\n",
        "print(f\"y_test shape: {y_test.shape} (NaN: {np.isnan(y_test).sum()})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m num_columns = X.select_dtypes(include=[\u001b[33m'\u001b[39m\u001b[33mnumber\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      2\u001b[39m cat_columns = X.select_dtypes(include=[\u001b[33m'\u001b[39m\u001b[33mobject\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(cat_columns)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/openaq-anomaly-prediction/lib/python3.12/site-packages/pandas/core/frame.py:1218\u001b[39m, in \u001b[36mDataFrame.__repr__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1215\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m buf.getvalue()\n\u001b[32m   1217\u001b[39m repr_params = fmt.get_dataframe_repr_params()\n\u001b[32m-> \u001b[39m\u001b[32m1218\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mto_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrepr_params\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/openaq-anomaly-prediction/lib/python3.12/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/openaq-anomaly-prediction/lib/python3.12/site-packages/pandas/core/frame.py:1398\u001b[39m, in \u001b[36mDataFrame.to_string\u001b[39m\u001b[34m(self, buf, columns, col_space, header, index, na_rep, formatters, float_format, sparsify, index_names, justify, max_rows, max_cols, show_dimensions, decimal, line_width, min_rows, max_colwidth, encoding)\u001b[39m\n\u001b[32m   1379\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[33m\"\u001b[39m\u001b[33mdisplay.max_colwidth\u001b[39m\u001b[33m\"\u001b[39m, max_colwidth):\n\u001b[32m   1380\u001b[39m     formatter = fmt.DataFrameFormatter(\n\u001b[32m   1381\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1382\u001b[39m         columns=columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1396\u001b[39m         decimal=decimal,\n\u001b[32m   1397\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_string\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mline_width\u001b[49m\u001b[43m=\u001b[49m\u001b[43mline_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1402\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/openaq-anomaly-prediction/lib/python3.12/site-packages/pandas/io/formats/format.py:962\u001b[39m, in \u001b[36mDataFrameRenderer.to_string\u001b[39m\u001b[34m(self, buf, encoding, line_width)\u001b[39m\n\u001b[32m    959\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mformats\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstring\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StringFormatter\n\u001b[32m    961\u001b[39m string_formatter = StringFormatter(\u001b[38;5;28mself\u001b[39m.fmt, line_width=line_width)\n\u001b[32m--> \u001b[39m\u001b[32m962\u001b[39m string = \u001b[43mstring_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m save_to_buffer(string, buf=buf, encoding=encoding)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/openaq-anomaly-prediction/lib/python3.12/site-packages/pandas/io/formats/string.py:29\u001b[39m, in \u001b[36mStringFormatter.to_string\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto_string\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     text = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_string_representation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fmt.should_show_dimensions:\n\u001b[32m     31\u001b[39m         text = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.fmt.dimensions_info\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/openaq-anomaly-prediction/lib/python3.12/site-packages/pandas/io/formats/string.py:44\u001b[39m, in \u001b[36mStringFormatter._get_string_representation\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fmt.frame.empty:\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._empty_info_line\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m strcols = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_strcols\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.line_width \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     47\u001b[39m     \u001b[38;5;66;03m# no need to wrap around just print the whole frame\u001b[39;00m\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.adj.adjoin(\u001b[32m1\u001b[39m, *strcols)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/openaq-anomaly-prediction/lib/python3.12/site-packages/pandas/io/formats/string.py:35\u001b[39m, in \u001b[36mStringFormatter._get_strcols\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_strcols\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]]:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     strcols = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_strcols\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fmt.is_truncated:\n\u001b[32m     37\u001b[39m         strcols = \u001b[38;5;28mself\u001b[39m._insert_dot_separators(strcols)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/openaq-anomaly-prediction/lib/python3.12/site-packages/pandas/io/formats/format.py:476\u001b[39m, in \u001b[36mDataFrameFormatter.get_strcols\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_strcols\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]]:\n\u001b[32m    473\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m    Render a DataFrame to a list of columns (as lists of strings).\u001b[39;00m\n\u001b[32m    475\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m     strcols = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_strcols_without_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.index:\n\u001b[32m    479\u001b[39m         str_index = \u001b[38;5;28mself\u001b[39m._get_formatted_index(\u001b[38;5;28mself\u001b[39m.tr_frame)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/openaq-anomaly-prediction/lib/python3.12/site-packages/pandas/io/formats/format.py:740\u001b[39m, in \u001b[36mDataFrameFormatter._get_strcols_without_index\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    736\u001b[39m cheader = str_columns[i]\n\u001b[32m    737\u001b[39m header_colwidth = \u001b[38;5;28mmax\u001b[39m(\n\u001b[32m    738\u001b[39m     \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m.col_space.get(c, \u001b[32m0\u001b[39m)), *(\u001b[38;5;28mself\u001b[39m.adj.len(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m cheader)\n\u001b[32m    739\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m740\u001b[39m fmt_values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_col\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    741\u001b[39m fmt_values = _make_fixed_width(\n\u001b[32m    742\u001b[39m     fmt_values, \u001b[38;5;28mself\u001b[39m.justify, minimum=header_colwidth, adj=\u001b[38;5;28mself\u001b[39m.adj\n\u001b[32m    743\u001b[39m )\n\u001b[32m    745\u001b[39m max_len = \u001b[38;5;28mmax\u001b[39m(*(\u001b[38;5;28mself\u001b[39m.adj.len(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m fmt_values), header_colwidth)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/openaq-anomaly-prediction/lib/python3.12/site-packages/pandas/io/formats/format.py:754\u001b[39m, in \u001b[36mDataFrameFormatter.format_col\u001b[39m\u001b[34m(self, i)\u001b[39m\n\u001b[32m    752\u001b[39m frame = \u001b[38;5;28mself\u001b[39m.tr_frame\n\u001b[32m    753\u001b[39m formatter = \u001b[38;5;28mself\u001b[39m._get_formatter(i)\n\u001b[32m--> \u001b[39m\u001b[32m754\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformat_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    755\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    756\u001b[39m \u001b[43m    \u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    757\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    758\u001b[39m \u001b[43m    \u001b[49m\u001b[43mna_rep\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mna_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    759\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcol_space\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    761\u001b[39m \u001b[43m    \u001b[49m\u001b[43mleading_space\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    762\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/openaq-anomaly-prediction/lib/python3.12/site-packages/pandas/io/formats/format.py:1161\u001b[39m, in \u001b[36mformat_array\u001b[39m\u001b[34m(values, formatter, float_format, na_rep, digits, space, justify, decimal, leading_space, quoting, fallback_formatter)\u001b[39m\n\u001b[32m   1145\u001b[39m     digits = get_option(\u001b[33m\"\u001b[39m\u001b[33mdisplay.precision\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1147\u001b[39m fmt_obj = fmt_klass(\n\u001b[32m   1148\u001b[39m     values,\n\u001b[32m   1149\u001b[39m     digits=digits,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1158\u001b[39m     fallback_formatter=fallback_formatter,\n\u001b[32m   1159\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmt_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/openaq-anomaly-prediction/lib/python3.12/site-packages/pandas/io/formats/format.py:1194\u001b[39m, in \u001b[36m_GenericArrayFormatter.get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1193\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_result\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m-> \u001b[39m\u001b[32m1194\u001b[39m     fmt_values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_strings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1195\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _make_fixed_width(fmt_values, \u001b[38;5;28mself\u001b[39m.justify)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/openaq-anomaly-prediction/lib/python3.12/site-packages/pandas/io/formats/format.py:1472\u001b[39m, in \u001b[36mFloatArrayFormatter._format_strings\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1471\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_format_strings\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m-> \u001b[39m\u001b[32m1472\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_result_as_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/openaq-anomaly-prediction/lib/python3.12/site-packages/pandas/io/formats/format.py:1439\u001b[39m, in \u001b[36mFloatArrayFormatter.get_result_as_array\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1436\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1437\u001b[39m     float_format = \u001b[38;5;28;01mlambda\u001b[39;00m value: \u001b[38;5;28mself\u001b[39m.float_format % value\n\u001b[32m-> \u001b[39m\u001b[32m1439\u001b[39m formatted_values = \u001b[43mformat_values_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1441\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fixed_width:\n\u001b[32m   1442\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m formatted_values\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/openaq-anomaly-prediction/lib/python3.12/site-packages/pandas/io/formats/format.py:1419\u001b[39m, in \u001b[36mFloatArrayFormatter.get_result_as_array.<locals>.format_values_with\u001b[39m\u001b[34m(float_format)\u001b[39m\n\u001b[32m   1417\u001b[39m         result = _trim_zeros_complex(values, \u001b[38;5;28mself\u001b[39m.decimal)\n\u001b[32m   1418\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1419\u001b[39m         result = \u001b[43m_trim_zeros_float\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1420\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.asarray(result, dtype=\u001b[33m\"\u001b[39m\u001b[33mobject\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/openaq-anomaly-prediction/lib/python3.12/site-packages/pandas/io/formats/format.py:1835\u001b[39m, in \u001b[36m_trim_zeros_float\u001b[39m\u001b[34m(str_floats, decimal)\u001b[39m\n\u001b[32m   1831\u001b[39m     trimmed = [x[:-\u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m is_number_with_decimal(x) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m trimmed]\n\u001b[32m   1833\u001b[39m \u001b[38;5;66;03m# leave one 0 after the decimal points if need be.\u001b[39;00m\n\u001b[32m   1834\u001b[39m result = [\n\u001b[32m-> \u001b[39m\u001b[32m1835\u001b[39m     x + \u001b[33m\"\u001b[39m\u001b[33m0\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_number_with_decimal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m x.endswith(decimal) \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[32m   1836\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m trimmed\n\u001b[32m   1837\u001b[39m ]\n\u001b[32m   1838\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/openaq-anomaly-prediction/lib/python3.12/site-packages/pandas/io/formats/format.py:1817\u001b[39m, in \u001b[36m_trim_zeros_float.<locals>.is_number_with_decimal\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   1816\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mis_number_with_decimal\u001b[39m(x) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1817\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mre\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber_regex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.11/lib/python3.12/re/__init__.py:167\u001b[39m, in \u001b[36mmatch\u001b[39m\u001b[34m(pattern, string, flags)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmatch\u001b[39m(pattern, string, flags=\u001b[32m0\u001b[39m):\n\u001b[32m    165\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Try to apply the pattern at the start of the string, returning\u001b[39;00m\n\u001b[32m    166\u001b[39m \u001b[33;03m    a Match object, or None if no match was found.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m.match(string)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.11/lib/python3.12/re/__init__.py:291\u001b[39m, in \u001b[36m_compile\u001b[39m\u001b[34m(pattern, flags)\u001b[39m\n\u001b[32m    289\u001b[39m key = (\u001b[38;5;28mtype\u001b[39m(pattern), pattern, flags)\n\u001b[32m    290\u001b[39m \u001b[38;5;66;03m# Item in _cache should be moved to the end if found.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m p = \u001b[43m_cache\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pattern, Pattern):\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "num_columns = X.select_dtypes(include=['number'])\n",
        "cat_columns = X.select_dtypes(include=['object'])\n",
        "\n",
        "print(num_columns)\n",
        "print(cat_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "cat_pipeline = Pipeline([\n",
        "    ('ohe', OneHotEncoder())\n",
        "])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "T-oLDv12B__e",
        "5F8dB-HJeig2",
        "A6WXD9syg5gt",
        "X3oNRX3fem51"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "openaq-anomaly-prediction",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
