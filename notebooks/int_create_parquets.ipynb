{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa72fe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import glob\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "from openaq_anomaly_prediction.config import Configuration as cfg\n",
    "# from openaq_anomaly_prediction.utils.helpers import concat_csv_to_csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9f9dca",
   "metadata": {},
   "source": [
    "### Concatenate 2 parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f381b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CITY_NAME = \"seoul\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c27b8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/deniscck/code/denis-cck/openaq_anomaly_prediction/data/csv/seoul_2024_measurements.int.parquet',\n",
      " '/home/deniscck/code/denis-cck/openaq_anomaly_prediction/data/csv/seoul_2025_measurements.int.parquet']\n"
     ]
    }
   ],
   "source": [
    "# CONCATENATE: Concatenate several trimesters CSVs into a single CSV file\n",
    "\n",
    "staging_csv_prefix = f\"{CITY_NAME}_2025\"\n",
    "\n",
    "selected_files = glob.glob(os.path.join(cfg.DATA_CSV_PATH, f\"{CITY_NAME}*_measurements.int.parquet\"))\n",
    "pprint(selected_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd80f048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/deniscck/code/denis-cck/openaq_anomaly_prediction/data/csv/seoul_2024_measurements.int.parquet into PyArrow Table: 2569852 rows...\n",
      "Reading /home/deniscck/code/denis-cck/openaq_anomaly_prediction/data/csv/seoul_2025_measurements.int.parquet into PyArrow Table: 3193431 rows...\n",
      "Concatenating PyArrow Tables: 5763283 total rows...\n",
      "Row count verified after concatenation.\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import os\n",
    "\n",
    "output_file_path = os.path.join(cfg.DATA_CSV_PATH, f\"{CITY_NAME}_measurements_concatenated.parquet\")\n",
    "\n",
    "# # --- Configuration ---\n",
    "# file_path_1 = 'file1.parquet'\n",
    "# file_path_2 = 'file2.parquet'\n",
    "# output_file_path = 'pyarrow_concatenated_output.parquet'\n",
    "\n",
    "# Ensure the files exist (create dummy files if they don't for testing)\n",
    "# This is just a setup block for a runnable example\n",
    "# if not os.path.exists(file_path_1):\n",
    "#     print(\"Creating dummy files for demonstration...\")\n",
    "#     dummy_df1 = pa.table({'col_A': [1, 2], 'col_B': ['x', 'y']})\n",
    "#     pq.write_table(dummy_df1, file_path_1)\n",
    "#     dummy_df2 = pa.table({'col_A': [3, 4], 'col_B': ['z', 'w']})\n",
    "#     pq.write_table(dummy_df2, file_path_2)\n",
    "\n",
    "total_rows = 0\n",
    "tables_to_concatenate = []\n",
    "for file_path in selected_files:\n",
    "    table = pq.read_table(file_path)\n",
    "    print(f\"Reading {file_path} into PyArrow Table: {table.num_rows} rows...\")\n",
    "    total_rows += table.num_rows\n",
    "    tables_to_concatenate.append(table)\n",
    "\n",
    "# # --- Step 1: Read the files into PyArrow Tables ---\n",
    "# print(f\"Reading {file_path_1} into PyArrow Table...\")\n",
    "# table1 = pq.read_table(file_path_1)\n",
    "\n",
    "# print(f\"Reading {file_path_2} into PyArrow Table...\")\n",
    "# table2 = pq.read_table(file_path_2)\n",
    "\n",
    "# --- Step 2: Concatenate the PyArrow Tables ---\n",
    "# pyarrow.concat_tables combines them efficiently\n",
    "concatenated_table = pa.concat_tables(tables_to_concatenate)\n",
    "\n",
    "print(f\"Concatenating PyArrow Tables: {concatenated_table.num_rows} total rows...\")\n",
    "if concatenated_table.num_rows != total_rows:\n",
    "    print(\"Row count mismatch after concatenation!\")\n",
    "else:\n",
    "    print(\"Row count verified after concatenation.\")\n",
    "\n",
    "    pq.write_table(concatenated_table, output_file_path)\n",
    "\n",
    "# # Optional: Print info about the result\n",
    "# print(\"\\n--- Summary ---\")\n",
    "# print(f\"Table 1 rows: {table1.num_rows}\")\n",
    "# print(f\"Table 2 rows: {table2.num_rows}\")\n",
    "# print(f\"Total concatenated rows: {concatenated_table.num_rows}\")\n",
    "# print(\"-----------------\\n\")\n",
    "\n",
    "# # --- Step 3: Write the concatenated Table to a new Parquet file ---\n",
    "# print(f\"Writing concatenated data to {output_file_path}...\")\n",
    "# # Note: The PyArrow writer handles column compression and metadata automatically\n",
    "# pq.write_table(concatenated_table, output_file_path)\n",
    "\n",
    "# print(\"âœ… PyArrow concatenation complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openaq-anomaly-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
